{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DVAE.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xKkVG_1jfTEh","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","%cd /content/drive/My Drive/Colab Notebook/code"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p0yuIocpgKZV","colab_type":"text"},"source":["## Import lib"]},{"cell_type":"code","metadata":{"id":"FNkvLgZfgMOY","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from models import Unet_2levels, Dunet_2levels, DVAE_refiner, DVAE\n","from utils import load_DRIVE, get_generator, log_gaussian, get_mix_coef, get_my_metrics, topo_metric\n","from PIL import Image\n","import os\n","\n","# change accordingly whether you want to use GPU or CPU\n","DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RGaPKv5BhYP4","colab_type":"text"},"source":["## Set parammeter"]},{"cell_type":"code","metadata":{"id":"PhEAfyABhcjN","colab_type":"code","outputId":"c8f30695-28ba-4616-9760-de5f067bd674","executionInfo":{"status":"ok","timestamp":1574661764065,"user_tz":-420,"elapsed":7013,"user":{"displayName":"Tung Thanh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAKDUkVZxYA03XqZNBWJ5zlAB8g9c60HRYxEa33=s64","userId":"11902234073278437381"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# how to combine the loss terms L1 and L2, matters in models with refinement\n","MIX_COEFF_INIT  = 0.99\n","MIX_COEFF_DECAY = 0.005\n","MIX_COEFF_MIN   = 0.3\n","START_DECAY = 0\n","\n","# set train parameters\n","EPOCHS = 150\n","STEPS_PER_EPOCH = 300   # number of mini-batches fed at each epoch\n","BATCH_SIZE = 16         # number of patches per mini-batch\n","PATCH_SIZE = 64         # side dimension of each patch\n","SEED = 7\n","\n","# set the pipeline to be executed and hyperparameters\n","MODEL = 'DVAE_refiner'    # Unet, Dunet, DVAE_refiner\n","LOSS_TYPE = 'BCE'         # can be one of BCE, BCEw, FL\n","ZDIM = 100                # number of feature maps of the 3D encoding space (DVAE)\n","USE_PRETRAINED = True     # to use pretrained models instead of training\n","\n","# picking a model according to the selection\n","if MODEL == 'Unet':\n","    model = Unet_2levels().to(DEVICE)\n","elif MODEL == 'Dunet':\n","    model = Dunet_2levels().to(DEVICE)\n","else:\n","    model = DVAE_refiner(ZDIM).to(DEVICE)\n","  \n","print(\"Model uses GPU: \", next(model.parameters()).is_cuda)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Model uses GPU:  True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iHjWc33Ci17K","colab_type":"text"},"source":["## Loading\n","- Loading dataset: DRIVE\n","- Loading weight: if using pretrained model"]},{"cell_type":"code","metadata":{"id":"qn6_APCVi4Kb","colab_type":"code","colab":{}},"source":["# Load Drive dataset\n","dir_cur = os.getcwd()\n","train_X, train_Y, train_F, train_S, test_X, test_Y, test_F = load_DRIVE(PATCH_SIZE, dir_cur)\n","\n","# load weight\n","if USE_PRETRAINED:\n","  path = dir_cur + '/weights/' + MODEL.lower() + '_' + LOSS_TYPE.lower() + '_weights.pth'\n","  if (os.path.exists(path)):\n","    model.load_state_dict(torch.load(path))\n","  else:\n","    print(\"Error Loading weight: not found\")\n","\n","# # print size and type of parameters of Model's layer\n","# for param_tensor in model.state_dict():\n","#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"akMGANMkn9Xj","colab_type":"text"},"source":["## Evaluation model"]},{"cell_type":"code","metadata":{"id":"4tne4VTKoBqO","colab_type":"code","colab":{}},"source":["# get metrics for train and test sets\n","# print('Getting the evaluation metrics...')\n","model.eval()\n","train_segs = np.zeros(train_Y.shape)\n","test_segs = np.zeros(test_Y.shape)\n","train_infeasible = 0\n","train_wrong = 0\n","train_correct = 0\n","test_infeasible = 0\n","test_wrong = 0\n","test_correct = 0\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwIXHyb4_XjI","colab_type":"code","outputId":"e9db554a-0cfd-403e-bb0e-38c459e42382","executionInfo":{"status":"error","timestamp":1574662107135,"user_tz":-420,"elapsed":118612,"user":{"displayName":"Tung Thanh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAKDUkVZxYA03XqZNBWJ5zlAB8g9c60HRYxEa33=s64","userId":"11902234073278437381"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["with torch.no_grad():\n","  for i in range(train_X.shape[0]):\n","    img = torch.from_numpy(train_X[i,:,:]).unsqueeze(dim=0).unsqueeze(dim=0).float().to(DEVICE)\n","    gt = train_Y[i,:,:]\n","\n","    if MODEL=='Unet':\n","        seg = model(img)\n","    elif MODEL=='Dunet':\n","        _, seg = model(img)\n","    else:\n","        _,_,_,_, seg = model(img, phase='test')\n","    a,b,c = topo_metric(gt, seg.cpu().numpy()[0,0], 0.5, 1000)\n","\n","    train_infeasible += a\n","    train_wrong += b\n","    train_correct += c   \n","\n","    train_segs[i] = seg"],"execution_count":6,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-5675e4f519fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrain_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_segs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Wrap Numpy array again in a suitable tensor when done, to support e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}]},{"cell_type":"code","metadata":{"id":"f8FF54jHBylk","colab_type":"code","colab":{}},"source":["with torch.no_grad():\n","  for i in range(test_X.shape[0]):\n","    img = torch.from_numpy(test_X[i,:,:]).unsqueeze(dim=0).unsqueeze(dim=0).float().to(DEVICE)\n","    gt = test_Y[i,:,:]\n","\n","    if MODEL=='Unet':\n","      seg = model(img)\n","    elif MODEL=='Dunet':\n","      _, seg = model(img)\n","    else:\n","      _,_,_,_, seg = model(img, phase='test')\n","\n","    a,b,c = topo_metric(gt, seg.cpu().numpy()[0,0], 0.5, 1000)\n","\n","    test_infeasible += a\n","    test_wrong += b\n","    test_correct += c   \n","\n","    test_segs[i] = seg\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTmmESiNClgi","colab_type":"code","colab":{}},"source":["  train_auc, train_acc, train_sen, train_spe = get_my_metrics(train_segs,train_Y,train_F)\n","  test_auc, test_acc, test_sen, test_spe = get_my_metrics(test_segs,test_Y,test_F)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lvYd12otDeyj","colab_type":"code","colab":{}},"source":["with torch.no_grad():\n","  img = torch.from_numpy(train_X[0,:,:]).unsqueeze(dim=0).unsqueeze(dim=0).float().to(DEVICE)\n","  gt = train_Y[0,:,:]\n","  _,_,_,_, seg = model(img, phase='test')\n","  a,b,c = topo_metric(gt, seg.cpu().numpy()[0,0], 0.5, 1000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TsWPj7tDl8l","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}